{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b7204bd-3674-448e-b055-1f1eea5b38cd",
   "metadata": {},
   "source": [
    "this code is to solve errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914f1173-0405-4594-8242-ccb1692dd87c",
   "metadata": {},
   "source": [
    "this part of code is to move the colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ec862ea4-3ee4-466a-8faa-78dda85c3f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 26)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cols = merged_df.columns.tolist()\n",
    "cols.remove('Clasify_IA_4')\n",
    "merged_df_v1 = merged_df[cols + ['Clasify_IA_4']]\n",
    "merged_df_v1.shape\n",
    "#merged_df_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1c50ee-e04b-4575-a6da-582b46cdd034",
   "metadata": {},
   "source": [
    "Export dataframe to a file xlxs is a better option to create a new table o Big Query just make this part whe all data is jointed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d6624a6-5424-41ce-a970-a1e466712048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is on file : ok\n"
     ]
    }
   ],
   "source": [
    "merged_df.to_excel('data/data_open_ia.xlsx',index=False)\n",
    "print('data is on file : ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c79edbfa-36d3-4316-84fd-34512bf63cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data : ok\n"
     ]
    }
   ],
   "source": [
    "# source data\n",
    "table_name = 'datalake-analytics-339922.UniDataSentiment.sss_onsite_gpt'\n",
    "print(\"source data : ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbd36a7a-45a9-4686-8442-f7599a7208fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crea una lista vacía para almacenar los nombres de las columnas que ya se han procesado\n",
    "columnas = [str(col) for col in merged_df.columns]\n",
    "columnas_tupla = [(col, \"STRING\", \"NULLABLE\") for col in columnas]\n",
    "schema = [bigquery.SchemaField(*col_tuple) for col_tuple in columnas_tupla]\n",
    "#for i in :\n",
    "    #columnas[i] =  columnas[i].apply(lambda x: x + '2')\n",
    "len(schema)\n",
    "#bigquery.SchemaField(\"col2\", \"STRING\", mode=\"NULLABLE\"),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5718bed3-b32d-4e7f-bc30-d4c3c57ffaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de la tabla en BigQuery\n",
    "\n",
    "\n",
    "# Crea una instancia de \"bigquery.Client\"\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Crea una instancia de \"bigquery.Table\" con el esquema y la tabla especificados\n",
    "table = bigquery.Table(table_name, schema=schema)\n",
    "\n",
    "# Crea la tabla en BigQuery\n",
    "table = client.create_table(table)  # API request\n",
    "print(f\"Created table {table.table_id}\")\n",
    "#datalake-analytics-339922.UniDataSentiment.sss_offsite_unidata_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5447c66e-55b8-459b-8861-88ba0638cdc6",
   "metadata": {},
   "source": [
    "upload the data  on bigquery  Nota : Use the method \"append\" to joint info without \"replace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b0e2fd6-8cda-4e98-9c08-f42d2a909e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5216.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe is : ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convierte todas las columnas del DataFrame a tipo \"string\"\n",
    "df =merged_df.astype(str)\n",
    "df.to_gbq(table_name, if_exists='replace')\n",
    "print (\"dataframe is : ok\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "local-pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
