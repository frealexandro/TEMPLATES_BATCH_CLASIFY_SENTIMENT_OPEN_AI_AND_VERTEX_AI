{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d66a580a-c563-42c7-962c-dab8918130e5",
   "metadata": {},
   "source": [
    "install dependencys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e0265c-2396-4b3d-8f4f-7c7c2e5613ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./.local/lib/python3.7/site-packages (0.25.0)\n",
      "Requirement already satisfied: pandas-stubs>=1.1.0.11 in ./.local/lib/python3.7/site-packages (from openai) (1.2.0.62)\n",
      "Requirement already satisfied: pandas>=1.2.3 in /opt/conda/lib/python3.7/site-packages (from openai) (1.3.5)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from openai) (1.21.6)\n",
      "Requirement already satisfied: openpyxl>=3.0.7 in ./.local/lib/python3.7/site-packages (from openai) (3.0.10)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.7/site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: et-xmlfile in ./.local/lib/python3.7/site-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.2.3->openai) (2022.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.16.0)\n",
      "Requirement already satisfied: openpyxl in ./.local/lib/python3.7/site-packages (3.0.10)\n",
      "Requirement already satisfied: et-xmlfile in ./.local/lib/python3.7/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: pandas-gbq in ./.local/lib/python3.7/site-packages (0.18.1)\n",
      "Requirement already satisfied: pydata-google-auth>=1.4.0 in ./.local/lib/python3.7/site-packages (from pandas-gbq) (1.4.0)\n",
      "Requirement already satisfied: pyarrow>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from pandas-gbq) (10.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from pandas-gbq) (1.21.6)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.10.2 in ./.local/lib/python3.7/site-packages (from pandas-gbq) (2.11.0)\n",
      "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in ./.local/lib/python3.7/site-packages (from pandas-gbq) (1.0.5)\n",
      "Requirement already satisfied: google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5 in ./.local/lib/python3.7/site-packages (from pandas-gbq) (3.4.1)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage<3.0.0dev,>=2.16.2 in /opt/conda/lib/python3.7/site-packages (from pandas-gbq) (2.16.2)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.7/site-packages (from pandas-gbq) (1.3.5)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from pandas-gbq) (0.7.0)\n",
      "Requirement already satisfied: google-auth>=2.13.0 in ./.local/lib/python3.7/site-packages (from pandas-gbq) (2.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from pandas-gbq) (59.8.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.7/site-packages (from db-dtypes<2.0.0,>=1.0.4->pandas-gbq) (21.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (1.56.4)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (2.28.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.7/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (4.21.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth>=2.13.0->pandas-gbq) (0.2.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=2.13.0->pandas-gbq) (5.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=2.13.0->pandas-gbq) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth>=2.13.0->pandas-gbq) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib>=0.7.0->pandas-gbq) (1.3.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in ./.local/lib/python3.7/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas-gbq) (1.22.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas-gbq) (1.50.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas-gbq) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas-gbq) (2.8.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas-gbq) (2.4.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.1.4->pandas-gbq) (2022.5)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (1.48.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas-gbq) (1.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=17.0->db-dtypes<2.0.0,>=1.0.4->pandas-gbq) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.13.0->pandas-gbq) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (3.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas-gbq) (3.2.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas-gbq) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas-gbq) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install openai --user\n",
    "!pip install openpyxl\n",
    "!pip install requests\n",
    "!pip install pandas-gbq --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df243204-f57d-4398-92a8-81767fcc1ad3",
   "metadata": {},
   "source": [
    "Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24d672e9-3398-4abc-9f69-eda752119041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datalake-analytics-339922'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43188b6-9320-4e85-9279-8d74ba756090",
   "metadata": {},
   "source": [
    "Input data by Big Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af7ba86-117d-41e3-99a8-513b562111d1",
   "metadata": {},
   "source": [
    "packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9eaf59e-0923-46dc-82f5-639adc2b1eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packages is: ok\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import requests\n",
    "import os\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "print(\"packages is: ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629c0232-f2e1-402d-8e29-c4297b2c2320",
   "metadata": {},
   "source": [
    "clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a49deb21-0906-4bcc-abd7-48d016575a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client is: ok\n"
     ]
    }
   ],
   "source": [
    "bq = bigquery.Client(project = PROJECT_ID)\n",
    "print(\"client is: ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6395ccde-5bba-4b0b-b137-bf1fcea5c560",
   "metadata": {},
   "source": [
    "Data on bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25592f61-8eb3-4f2d-ad54-1d26dd9637eb",
   "metadata": {},
   "source": [
    "Input Data by file xlxs, the first time you run the program try to change the file 'data/clasification.xlsx' and then use this path 'data/data_open_ia.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ca875eb-8e00-4160-a992-a54696fe4606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2541, 27)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bq_2 = pd.read_excel('data/data_open_ia.xlsx')\n",
    "\n",
    "df_bq_2.shape\n",
    "#df_bq_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ea7c4-9cff-4488-95d5-51720e85c7d7",
   "metadata": {},
   "source": [
    "clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39308bd3-f065-4432-b48a-7c1ea478b062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe filtred is :ok\n"
     ]
    }
   ],
   "source": [
    "#depend what source do you need your will change the name of data frame\n",
    "#source from Big Query : df_bq_1\n",
    "#source from file xlxs : df_bq_2\n",
    "\n",
    "dfcln = df_bq_2[['Id_Model','Message_x_x_x_x_x']]\n",
    "print(\"dataframe filtred is :ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce247c16-34e5-42f1-af05-6523b041f8d2",
   "metadata": {},
   "source": [
    "variables open ia:\n",
    "\n",
    "-ia1 : Message\n",
    "-ia2 : Message_x\n",
    "-ia3 : Message_x_x\n",
    "-ia4 : Message_x_x_x\n",
    "-ia5 : Message_x_x_x_x\n",
    "-ia6 : Message_x_x_x_x_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0235c4e-acdc-4736-b9f8-a13fcf193e87",
   "metadata": {},
   "source": [
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1136894d-3a41-4f45-aae9-55dec5747a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index                             Id_Model            Message_x_x_x_x_x\n",
      "0      0  model23020913071100000001879escv5f\"          Team Bad Bunny !¡!!\n",
      "1      1  model23020913071100000001880escv5f\"  Trepadora Social y clasista\n",
      "2      2  model23020913071100000001881escv5f\"                 GIFS o Fotos\n",
      "3      3  model23020913071100000001882escv5f\"                         💖💖💖💖\n",
      "4      4  model23020913071100000001883escv5f\"                 GIFS o Fotos\n",
      "posts is : ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch = dfcln.iloc[0:1000]\n",
    "first_batch.astype(str)\n",
    "bct_inx = first_batch.reset_index()\n",
    "print(bct_inx.head())\n",
    "#lista\n",
    "posts = first_batch['Message_x_x_x_x_x'].tolist()\n",
    "print('posts is : ok')\n",
    "len(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74b752-45df-455d-83cc-d0ae34fb8397",
   "metadata": {},
   "source": [
    "make a batch open ia_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "405d9d4c-1cb4-46fd-9892-a35e7b1436a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is :ok\n",
      "primera lista is :ok\n",
      "341\n",
      "341\n",
      "341\n",
      "clasify is okey\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Inicializar la API de OpenAI\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Definir el modelo y el prompt que quieres utilizar\n",
    "model_engine = \"text-davinci-002\"\n",
    "prompt = \"Describa el tono o emoción mostrado en el siguiente titular:(Rabia, Disgusto, Miedo, Alegría, Tristeza, Ninguno): \"\n",
    "\n",
    "\n",
    "# Crear una lista de titulares para tu \"batch\"\n",
    "\n",
    "\n",
    "\n",
    "# Crear una lista vacía para almacenar las respuestas\n",
    "responses = []\n",
    "\n",
    "# Realizar una petición para cada título en la lista\n",
    "for title in posts:\n",
    "    response = openai.Completion.create(\n",
    "        engine=model_engine,\n",
    "        prompt=prompt + str(title),\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "        \n",
    "    )\n",
    "    \n",
    "    responses.append(response.choices[0].text)\n",
    "print(\"data is :ok\")\n",
    "\n",
    "#clean response\n",
    "# Podemos usar una regex y la función \"re.sub()\" para reemplazar todas las ocurrencias de \"\\n\\n\"\n",
    "mi_lista_1 = [re.sub('\\n\\n', '', x) for x in responses]\n",
    "print(\"primera lista is :ok\")\n",
    "print(len(mi_lista_1))\n",
    "\n",
    "#joint to dataframe\n",
    "#we joint this df by index\n",
    "df_text_davinci_002 = pd.DataFrame(mi_lista_1, columns=['Clasify_IA_1'])\n",
    "print(len(df_text_davinci_002))\n",
    "df_num = pd.DataFrame()\n",
    "df_num = df_num.fillna(0)\n",
    "for i in df_text_davinci_002.columns:\n",
    "    df_num[i] = df_text_davinci_002 [i].str.extract(r'(Rabia|Disgusto|Miedo|Alegría|Tristeza|Ninguno)')\n",
    "#df_text_davinci_002\n",
    "\n",
    "df_num_v1 = df_num.fillna(\"Ninguno\")\n",
    "last_df = pd.concat([df_num_v1, bct_inx], axis=1)\n",
    "print(len(last_df))\n",
    "print('clasify is okey')\n",
    "#last_df.tail()\n",
    "\n",
    "result = pd.merge(left=df_bq_2, right=last_df, left_on='Id_Model', right_on='Id_Model', how='right')\n",
    "#df_result_v1=fix_error\n",
    "\n",
    "\n",
    "#df_result = result.drop(result.index[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4a164020-62fd-4837-94fe-a9b16e12a09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341, 23)\n"
     ]
    }
   ],
   "source": [
    "df_result_v1 = result.drop([\"Message_y\",\"index\"], axis=1)\n",
    "print(df_result_v1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012e5ccf-1cc2-4307-bab3-3a3132a71775",
   "metadata": {},
   "source": [
    "make a batch open ia 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bc1a410-fc5e-49e3-8675-8e3839118c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is :ok\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Inicializar la API de OpenAI\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Definir el modelo y el prompt que quieres utilizar\n",
    "model_engine = \"text-davinci-002\"\n",
    "prompt = \"Diga cual es el sentimiento expresado en el siguiente titular (Positivo,Negativo,Neutro):\"\n",
    "\n",
    "\n",
    "# Crear una lista de titulares para tu \"batch\"\n",
    "\n",
    "\n",
    "\n",
    "# Crear una lista vacía para almacenar las respuestas\n",
    "responses = []\n",
    "\n",
    "# Realizar una petición para cada título en la lista\n",
    "for title in posts:\n",
    "    response = openai.Completion.create(\n",
    "        engine=model_engine,\n",
    "        prompt=prompt + str(title),\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "        \n",
    "    )\n",
    "    \n",
    "    responses.append(response.choices[0].text)\n",
    "print(\"data is :ok\")\n",
    "\n",
    "\n",
    "#df_result = result.drop(result.index[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01ef0e82-ed12-4efa-b1af-1fab28c8335c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primera lista is :ok\n",
      "541\n",
      "541\n",
      "clasify is okey\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(541, 24)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#clean response\n",
    "# Podemos usar una regex y la función \"re.sub()\" para reemplazar todas las ocurrencias de \"\\n\\n\"\n",
    "mi_lista_1 = [re.sub('\\n\\n', '', x) for x in responses]\n",
    "print(\"primera lista is :ok\")\n",
    "len(mi_lista_1)\n",
    "\n",
    "#joint to dataframe\n",
    "#we joint this df by index\n",
    "df_text_davinci_002 = pd.DataFrame(mi_lista_1, columns=['Clasify_IA_2'])\n",
    "print(len(df_text_davinci_002))\n",
    "df_num = pd.DataFrame()\n",
    "df_num = df_num.fillna(0)\n",
    "for i in df_text_davinci_002.columns:\n",
    "    df_num[i] = df_text_davinci_002 [i].str.extract(r'(Positivo|Negativo|Neutro)')\n",
    "#df_text_davinci_002\n",
    "\n",
    "df_num_v1 = df_num.fillna(\"Ninguno\")\n",
    "last_df = pd.concat([df_num_v1, bct_inx], axis=1)\n",
    "print(len(last_df))\n",
    "print('clasify is okey')\n",
    "result = pd.merge(left=df_bq_2, right=last_df, left_on='Id_Model', right_on='Id_Model', how='right')\n",
    "\n",
    "result\n",
    "df_result_v1 = result.drop([\"Message_x_y\",\"index\"], axis=1)\n",
    "df_result_v1.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d773d6b7-2211-4659-87b2-f3948f94c1e9",
   "metadata": {},
   "source": [
    "make a batch ia3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6778e0a-26aa-41bd-a43c-b0e4afe98b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is :ok\n",
      "primera lista is :ok\n",
      "541\n",
      "541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(541, 25)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Inicializar la API de OpenAI\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Definir el modelo y el prompt que quieres utilizar\n",
    "model_engine = \"text-davinci-002\"\n",
    "prompt = \"Diga cuales son las tres palabras claves del siguiente texto en orden de importancia de mayor a menor (X,X,X): \"\n",
    "\n",
    "\n",
    "# Crear una lista de titulares para tu \"batch\"\n",
    "\n",
    "\n",
    "\n",
    "# Crear una lista vacía para almacenar las respuestas\n",
    "responses = []\n",
    "\n",
    "# Realizar una petición para cada título en la lista\n",
    "for title in posts:\n",
    "    response = openai.Completion.create(\n",
    "        engine=model_engine,\n",
    "        prompt=prompt +str(title),\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "        \n",
    "    )\n",
    "    \n",
    "    responses.append(response.choices[0].text)\n",
    "print(\"data is :ok\")\n",
    "\n",
    "#clean response\n",
    "# Podemos usar una regex y la función \"re.sub()\" para reemplazar todas las ocurrencias de \"\\n\\n\"\n",
    "mi_lista_1 = [re.sub('\\n\\n|\\n|\\n2|\\n3|1.', '', x) for x in responses]\n",
    "print(\"primera lista is :ok\")\n",
    "print(len(mi_lista_1))\n",
    "\n",
    "#joint to dataframe\n",
    "#we joint this df by index\n",
    "df_text_davinci_002 = pd.DataFrame(mi_lista_1, columns=['Clasify_IA_3'])\n",
    "print(len(df_text_davinci_002))\n",
    "df_num_v1 = df_text_davinci_002.fillna(\"Ninguno\")\n",
    "last_df_1 = pd.concat([df_num_v1, bct_inx], axis=1)\n",
    "#print(last_df_1.shape)\n",
    "result = pd.merge(left=df_bq_2, right=last_df_1, left_on='Id_Model', right_on='Id_Model', how='right')\n",
    "df_result_v1 = result.drop([\"Message_x_x_y\",\"index\"], axis=1)\n",
    "df_result_v1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017c556e-f12c-42ac-9b75-dd49ca5ff49e",
   "metadata": {},
   "source": [
    "make a batch ia4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9dd6eff2-f528-4baa-aac2-864c3a81df96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is :ok\n",
      "primera lista is :ok\n",
      "541\n",
      "541\n",
      "clasify is okey\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(541, 26)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Inicializar la API de OpenAI\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Definir el modelo y el prompt que quieres utilizar\n",
    "model_engine = \"text-davinci-002\"\n",
    "prompt = \"Defina una categoría que permita saber el siguiente texto a cual de ellas pertenece en orden de afinidad (Ciencia, Cobertura, Cultura, Economía,Educación, Finanzas, Ley y Justicia, Medio Ambiente, Negocios, Política, Promociones,Quejas, Salud, Satisfacción del cliente, Tecnología, Turismo, Vivienda): \"\n",
    "\n",
    "\n",
    "# Crear una lista de titulares para tu \"batch\"\n",
    "\n",
    "\n",
    "\n",
    "# Crear una lista vacía para almacenar las respuestas\n",
    "responses = []\n",
    "\n",
    "# Realizar una petición para cada título en la lista\n",
    "for title in posts:\n",
    "    response = openai.Completion.create(\n",
    "        engine=model_engine,\n",
    "        prompt=prompt +str(title),\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "        \n",
    "    )\n",
    "    \n",
    "    responses.append(response.choices[0].text)\n",
    "print(\"data is :ok\")\n",
    "\n",
    "#clean response\n",
    "# Podemos usar una regex y la función \"re.sub()\" para reemplazar todas las ocurrencias de \"\\n\\n\"\n",
    "mi_lista_1 = [re.sub('\\n\\n|\\n|\\n2|\\n3|1.', '', x) for x in responses]\n",
    "print(\"primera lista is :ok\")\n",
    "len(mi_lista_1)\n",
    "\n",
    "#joint to dataframe\n",
    "#we joint this df by index\n",
    "df_text_davinci_002 = pd.DataFrame(mi_lista_1, columns=['Clasify_IA_4'])\n",
    "print(len(df_text_davinci_002))\n",
    "df_num = pd.DataFrame()\n",
    "df_num = df_num.fillna(0)\n",
    "for i in df_text_davinci_002.columns:\n",
    "    df_num[i] = df_text_davinci_002 [i].str.extract(r'(Ciencia|Cobertura|Cultura|Economía|Educación|Finanzas|Ley y Justicia|Medio Ambiente|Negocios|Política|Promociones|Quejas|Salud|Satisfacción del cliente|Tecnología|Turismo|Vivienda)')\n",
    "#df_text_davinci_002\n",
    "\n",
    "df_num_v1 = df_num.fillna(\"Ninguno\")\n",
    "last_df = pd.concat([df_num_v1, bct_inx], axis=1)\n",
    "print(len(last_df))\n",
    "print('clasify is okey')\n",
    "last_df.tail()\n",
    "result = pd.merge(left=df_bq_2, right=last_df, left_on='Id_Model', right_on='Id_Model', how='right')\n",
    "\n",
    "#result\n",
    "df_result_v1 = result.drop([\"Message_x_x_x_y\",\"index\"], axis=1)\n",
    "df_result_v1.shape\n",
    "#df_result = result.drop(result.index[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5ca36f-a481-43c5-a1a7-5e3f978292a5",
   "metadata": {},
   "source": [
    "make a batch ia5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4e7b675c-81d7-440f-9526-43507e78187c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is :ok\n",
      "primera lista is :ok\n",
      "541\n",
      "541\n",
      "541\n",
      "clasify is okey\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(541, 27)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Inicializar la API de OpenAI\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Definir el modelo y el prompt que quieres utilizar\n",
    "model_engine = \"text-davinci-002\"\n",
    "prompt = \"Describa el tono o emoción mostrado en el siguiente titular (Sorpresa, Alegría, Satisfacción, Admiración, Curiosidad, Tristeza, Aversión, Enojo, Miedo, Amor, Ansiedad, Ninguno):\"\n",
    "\n",
    "\n",
    "# Crear una lista de titulares para tu \"batch\"\n",
    "\n",
    "\n",
    "\n",
    "# Crear una lista vacía para almacenar las respuestas\n",
    "responses = []\n",
    "\n",
    "# Realizar una petición para cada título en la lista\n",
    "for title in posts:\n",
    "    response = openai.Completion.create(\n",
    "        engine=model_engine,\n",
    "        prompt=prompt +str(title),\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "        \n",
    "    )\n",
    "    \n",
    "    responses.append(response.choices[0].text)\n",
    "print(\"data is :ok\")\n",
    "\n",
    "#clean response\n",
    "# Podemos usar una regex y la función \"re.sub()\" para reemplazar todas las ocurrencias de \"\\n\\n\"\n",
    "mi_lista_1 = [re.sub('\\n\\n|\\n|\\n2|\\n3|1.', '', x) for x in responses]\n",
    "print(\"primera lista is :ok\")\n",
    "print(len(mi_lista_1))\n",
    "#joint to dataframe\n",
    "#we joint this df by index\n",
    "df_text_davinci_002 = pd.DataFrame(mi_lista_1, columns=['Clasify_IA_5'])\n",
    "print(len(df_text_davinci_002))\n",
    "df_num = pd.DataFrame()\n",
    "df_num = df_num.fillna(0)\n",
    "for i in df_text_davinci_002.columns:\n",
    "    df_num[i] = df_text_davinci_002 [i].str.extract(r'(Sorpresa|Alegría|Satisfacción|Admiración|Curiosidad|Tristeza|Aversión|Enojo|Miedo|Amor|Ansiedad|Ninguno)')\n",
    "#df_text_davinci_002#\n",
    "\n",
    "df_num_v1 = df_num.fillna(\"Ninguno\")\n",
    "last_df = pd.concat([df_num_v1, bct_inx], axis=1)\n",
    "print(len(last_df))\n",
    "print('clasify is okey')\n",
    "last_df.tail()\n",
    "result = pd.merge(left=df_bq_2, right=last_df, left_on='Id_Model', right_on='Id_Model', how='right')\n",
    "\n",
    "#result\n",
    "df_result_v1 = result.drop([\"Message_x_x_x_x_y\",\"index\"], axis=1)\n",
    "df_result_v1.shape\n",
    "#df_result = result.drop(result.index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f029018-9c30-4d74-8b42-56b45a3fd616",
   "metadata": {},
   "source": [
    "make a batch ia6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af15d0d-bd48-46c6-9999-118fa3dacd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the process started\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print ('the process started')\n",
    "# Inicializar la API de OpenAI\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Definir el modelo y el prompt que quieres utilizar\n",
    "model_engine = \"text-davinci-002\"\n",
    "prompt = \"cual de ellas pertenece en orden de afinidad(Adultos, Arte y Entretenimiento, Coches y Vehículos, Belleza y Fitness, Libros y literatura, Negocios e Industria, Informática y electrónica, Finanzas, Alimentación, Juegos, Salud, Ocio y tiempo libre, Hogar y jardín, Internet y Telecomunicaciones, Empleo y Educación, Derecho y Gobierno, Noticias, Comunidades en línea, Gente y sociedad, Animales y mascotas, Inmobiliaria, Referencia, Ciencia, Temas delicados, Compras, Deportes, Viajes y transportes):\"\n",
    "\n",
    "#Defina una categoría que permita saber el siguiente texto a \n",
    "# (): \"TEXT HERE\"\n",
    "# Crear una lista de titulares para tu \"batch\"\n",
    "\n",
    "\n",
    "\n",
    "# Crear una lista vacía para almacenar las respuestas\n",
    "responses = []\n",
    "\n",
    "# Realizar una petición para cada título en la lista\n",
    "for title in posts:\n",
    "    response = openai.Completion.create(\n",
    "        engine=model_engine,\n",
    "        prompt=prompt +str(title),\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "        \n",
    "    )\n",
    "    \n",
    "    responses.append(response.choices[0].text)\n",
    "    \n",
    "print(\"data is :ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fb00e0-faec-4cf6-aa4f-b073eb64ddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#clean response\n",
    "# Podemos usar una regex y la función \"re.sub()\" para reemplazar todas las ocurrencias de \"\\n\\n\"\n",
    "mi_lista_1 = [re.sub('\\n\\n|\\n|\\n2|\\n3|1.', '', x) for x in responses]\n",
    "print(\"primera lista is :ok\")\n",
    "print(len(mi_lista_1))\n",
    "#joint to dataframe\n",
    "#we joint this df by index\n",
    "df_text_davinci_002 = pd.DataFrame(mi_lista_1, columns=['Clasify_IA_6'])\n",
    "print(len(df_text_davinci_002))\n",
    "df_num = pd.DataFrame()\n",
    "df_num = df_num.fillna(0)\n",
    "for i in df_text_davinci_002.columns:\n",
    "    df_num[i] = df_text_davinci_002 [i].str.extract(r'(Adultos|Arte y Entretenimiento|Coches y Vehículos|Belleza y Fitness|Libros y literatura|Negocios e Industria|Informática y electrónica|Finanzas|Alimentación|Juegos|Salud|Ocio y tiempo libre|Hogar y jardín|Internet y Telecomunicaciones|Empleo y Educación|Derecho y Gobierno|Noticias|Comunidades en línea|Gente y sociedad|Animales y mascotas|Inmobiliaria|Referencia|Ciencia|Temas delicados|Compras|Deportes|Viajes y transportes)')\n",
    "#df_text_davinci_002#\n",
    "\n",
    "df_num_v1 = df_num.fillna(\"Ninguno\")\n",
    "last_df = pd.concat([df_num_v1, bct_inx], axis=1)\n",
    "print(len(last_df))\n",
    "print('clasify is okey')\n",
    "last_df.tail()\n",
    "result = pd.merge(left=df_bq_2, right=last_df, left_on='Id_Model', right_on='Id_Model', how='right')\n",
    "#print(result)\n",
    "#result\n",
    "\n",
    "#df_result = result.drop(result.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "94c4f070-0572-411e-be0a-4e31ce7fab88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 93)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_v1 = result.drop([\"Message_x_x_x_x_x_y\",\"index\"], axis=1)\n",
    "df_result_v1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f7386-d4cd-49e8-8695-2ae733620410",
   "metadata": {},
   "source": [
    "Assing the DataFrame processed to a new variable to contact with the df_final we just neeet to execute the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7c65fd6a-ca96-44a0-af58-949d34d17239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_final is ok\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.DataFrame()\n",
    "print('df_final is ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99407784-b7ba-4295-a322-4d4c85ed88c7",
   "metadata": {},
   "source": [
    "then to execute the first time the variable we change df_final by merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8cf7e15c-87f5-41d7-a414-698f4a457b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2541, 27)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df_result_v1\n",
    "merged_df = pd.concat([df1,merged_df], axis=0)\n",
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a5a77339-c053-4366-b55d-fb8396ea03ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_Model</th>\n",
       "      <th>User</th>\n",
       "      <th>Message_x_x_x_x_x</th>\n",
       "      <th>Brands</th>\n",
       "      <th>Subsidiary</th>\n",
       "      <th>Sentimiento</th>\n",
       "      <th>Topics 1</th>\n",
       "      <th>Topics 2</th>\n",
       "      <th>Topics 3</th>\n",
       "      <th>Locations</th>\n",
       "      <th>...</th>\n",
       "      <th>Post Id 2</th>\n",
       "      <th>First Admin Comment</th>\n",
       "      <th>Link</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Clasification_M</th>\n",
       "      <th>Clasify_IA_1</th>\n",
       "      <th>Clasify_IA_2</th>\n",
       "      <th>Clasify_IA_3</th>\n",
       "      <th>Clasify_IA_4</th>\n",
       "      <th>Clasify_IA_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model23020913071100000001879escv5f\"</td>\n",
       "      <td>Facebook User</td>\n",
       "      <td>Team Bad Bunny !¡!!</td>\n",
       "      <td>Point Guard</td>\n",
       "      <td>PROPIEDAD</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Comunicación oficial</td>\n",
       "      <td>Tendencias</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.facebook.com/556175296544659#chann...</td>\n",
       "      <td>1</td>\n",
       "      <td>Menciones generales</td>\n",
       "      <td>Alegría</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>Bad Bunny2. Team3. !¡!!</td>\n",
       "      <td>Cultura</td>\n",
       "      <td>Ninguno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model23020913071100000001880escv5f\"</td>\n",
       "      <td>Facebook User</td>\n",
       "      <td>Trepadora Social y clasista</td>\n",
       "      <td>Point Guard</td>\n",
       "      <td>PROPIEDAD</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Comunicación oficial</td>\n",
       "      <td>Tendencias</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.facebook.com/556175296544659#chann...</td>\n",
       "      <td>0</td>\n",
       "      <td>Institucional</td>\n",
       "      <td>Disgusto</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>social, clasista, trepadora</td>\n",
       "      <td>Política</td>\n",
       "      <td>Ninguno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model23020913071100000001881escv5f\"</td>\n",
       "      <td>Facebook User</td>\n",
       "      <td>GIFS o Fotos</td>\n",
       "      <td>Point Guard</td>\n",
       "      <td>PROPIEDAD</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Comunicación oficial</td>\n",
       "      <td>Tendencias</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.facebook.com/556175296544659#chann...</td>\n",
       "      <td>2</td>\n",
       "      <td>Institucional</td>\n",
       "      <td>Ninguno</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>GIFS2. Fotos3.</td>\n",
       "      <td>Cultura</td>\n",
       "      <td>Sorpresa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model23020913071100000001882escv5f\"</td>\n",
       "      <td>Facebook User</td>\n",
       "      <td>💖💖💖💖</td>\n",
       "      <td>Point Guard</td>\n",
       "      <td>PROPIEDAD</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Comunicación oficial</td>\n",
       "      <td>Tendencias</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.facebook.com/556175296544659#chann...</td>\n",
       "      <td>2</td>\n",
       "      <td>Comunicación oficial</td>\n",
       "      <td>Alegría</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>Bridget Jones's Diary is a 96 novel by Helen F...</td>\n",
       "      <td>Cultura</td>\n",
       "      <td>Amor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model23020913071100000001883escv5f\"</td>\n",
       "      <td>Facebook User</td>\n",
       "      <td>GIFS o Fotos</td>\n",
       "      <td>Point Guard</td>\n",
       "      <td>PROPIEDAD</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Comunicación oficial</td>\n",
       "      <td>Tendencias</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.facebook.com/556175296544659#chann...</td>\n",
       "      <td>2</td>\n",
       "      <td>Institucional</td>\n",
       "      <td>Ninguno</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>Fotos, GIFS, o</td>\n",
       "      <td>Ninguno</td>\n",
       "      <td>Alegría</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Id_Model           User  \\\n",
       "0  model23020913071100000001879escv5f\"  Facebook User   \n",
       "1  model23020913071100000001880escv5f\"  Facebook User   \n",
       "2  model23020913071100000001881escv5f\"  Facebook User   \n",
       "3  model23020913071100000001882escv5f\"  Facebook User   \n",
       "4  model23020913071100000001883escv5f\"  Facebook User   \n",
       "\n",
       "             Message_x_x_x_x_x       Brands Subsidiary Sentimiento  \\\n",
       "0          Team Bad Bunny !¡!!  Point Guard  PROPIEDAD     Neutral   \n",
       "1  Trepadora Social y clasista  Point Guard  PROPIEDAD     Neutral   \n",
       "2                 GIFS o Fotos  Point Guard  PROPIEDAD     Neutral   \n",
       "3                         💖💖💖💖  Point Guard  PROPIEDAD     Neutral   \n",
       "4                 GIFS o Fotos  Point Guard  PROPIEDAD     Neutral   \n",
       "\n",
       "               Topics 1    Topics 2 Topics 3  Locations  ... Post Id 2  \\\n",
       "0  Comunicación oficial  Tendencias      NaN        NaN  ...       NaN   \n",
       "1  Comunicación oficial  Tendencias      NaN        NaN  ...       NaN   \n",
       "2  Comunicación oficial  Tendencias      NaN        NaN  ...       NaN   \n",
       "3  Comunicación oficial  Tendencias      NaN        NaN  ...       NaN   \n",
       "4  Comunicación oficial  Tendencias      NaN        NaN  ...       NaN   \n",
       "\n",
       "   First Admin Comment                                               Link  \\\n",
       "0                  NaN  https://www.facebook.com/556175296544659#chann...   \n",
       "1                  NaN  https://www.facebook.com/556175296544659#chann...   \n",
       "2                  NaN  https://www.facebook.com/556175296544659#chann...   \n",
       "3                  NaN  https://www.facebook.com/556175296544659#chann...   \n",
       "4                  NaN  https://www.facebook.com/556175296544659#chann...   \n",
       "\n",
       "  Sentiment       Clasification_M  Clasify_IA_1 Clasify_IA_2  \\\n",
       "0         1   Menciones generales       Alegría     Positivo   \n",
       "1         0         Institucional      Disgusto     Negativo   \n",
       "2         2         Institucional       Ninguno       Neutro   \n",
       "3         2  Comunicación oficial       Alegría     Positivo   \n",
       "4         2         Institucional       Ninguno     Positivo   \n",
       "\n",
       "                                        Clasify_IA_3  Clasify_IA_4  \\\n",
       "0                            Bad Bunny2. Team3. !¡!!       Cultura   \n",
       "1                        social, clasista, trepadora      Política   \n",
       "2                                     GIFS2. Fotos3.       Cultura   \n",
       "3  Bridget Jones's Diary is a 96 novel by Helen F...       Cultura   \n",
       "4                                     Fotos, GIFS, o       Ninguno   \n",
       "\n",
       "  Clasify_IA_5  \n",
       "0      Ninguno  \n",
       "1      Ninguno  \n",
       "2     Sorpresa  \n",
       "3         Amor  \n",
       "4      Alegría  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada375a-1185-49af-a7a5-9d13dd85705a",
   "metadata": {},
   "source": [
    "Export dataframe to a file xlxs is a better option to create a new table o Big Query just make this part whe all data is jointed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1711d646-5505-4da4-a9d6-a1b5b00d9263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is on file : ok\n"
     ]
    }
   ],
   "source": [
    "merged_df.to_excel('data/data_open_ia.xlsx',index=False)\n",
    "print('data is on file : ok')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "local-pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
