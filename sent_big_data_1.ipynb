{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b8aa5c3",
   "metadata": {},
   "source": [
    "Dependencys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9e03710-788f-43ac-8849-ee960db56e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl\n",
    "!pip install requests\n",
    "!pip install pandas-gbq --user"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1454051",
   "metadata": {},
   "source": [
    "Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e48ce-9748-4cf3-9256-57150dd7ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform.gapic.schema import predict\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "from typing import Sequence, Union\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" This function performs a batch prediction job using the specified AI Platform model,\n",
    "    source and destination.Returns: output_files (List[str]): The names of the files in \n",
    "    the GCS destination location that contain the prediction results. \"\"\"\n",
    "\n",
    "\n",
    "def batch_prediction_job(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    model_resource_name: str,\n",
    "    job_display_name: str,\n",
    "    gcs_source: Union[str, Sequence[str]],\n",
    "    gcs_destination: str,\n",
    "    sync: bool = True,\n",
    "    ):\n",
    "    \n",
    "    \n",
    "    # Initialize the AI Platform client for the given project and location\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    # Get the AI Platform model to use for prediction\n",
    "    my_model = aiplatform.Model(model_resource_name)\n",
    "\n",
    "    # Submit the batch prediction job using the model, source, and destination\n",
    "    batch_prediction_job = my_model.batch_predict(\n",
    "        job_display_name=job_display_name,\n",
    "        gcs_source=gcs_source,\n",
    "        gcs_destination_prefix=gcs_destination,\n",
    "        sync=sync,\n",
    "    )\n",
    "    \n",
    "    # Get the names of the prediction results files in the GCS destination location\n",
    "    client = storage.Client(project=project)\n",
    "    bucket = client.bucket(gcs_destination.split(\"/\")[2])\n",
    "    blobs = bucket.list_blobs(prefix=gcs_destination.split(\"/\", 3)[-1])\n",
    "    output_files = [blob.name for blob in blobs]\n",
    "    \n",
    "    return output_files\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "class Param:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # path to the input file\n",
    "        self.file_input = 'gs://data_sentiment_v5/SSS/sss_onsite/on_site_2023/SSS DB Power BI - Sentimiento OnSite  1-5 Febrero 2023.xls\n",
    "        # project ID \n",
    "        self.project_id = \"28########04\"\n",
    "        # model ID for off-site sentiment analysis\n",
    "        self.model_id_off_site =\"58############88\"\n",
    "        # model ID for on-site sentiment analysis\n",
    "        self.model_id_on_site = \"35############28\"\n",
    "        # input URI for batch predictions\n",
    "        self.input_uri = \"gs://batch_predictions_sentiment/Prediction_Masive_Sentiment/Main_Control_Batch/Prediction_Main_Batch.jsonl\"\n",
    "        # output URI for batch predictions\n",
    "        self.output_uri = \"gs://batch_predictions_sentiment/Prediction_Masive_Sentiment/Output_batch/\"\n",
    "        # location for cloud services\n",
    "        self.location=\"us-central1\"\n",
    "        # display name for the batch prediction job\n",
    "        self.job_display_name = \"new_job\"\n",
    "        # path for processing batch data\n",
    "        self.Processing_Batch = 'gs://batch_predictions_sentiment/Prediction_Masive_Sentiment/Prosecing_Masive_Data/'\n",
    "        # path for main control batch data\n",
    "        self.Path_Control = 'gs://batch_predictions_sentiment/Prediction_Masive_Sentiment/Main_Control_Batch/'\n",
    "        # initial string for constructing the content URI\n",
    "        self.complement_ini = \"{\\'content\\' :\\'gs://batch_predictions_sentiment/Prediction_Masive_Sentiment/Prosecing_Masive_Data/\"\n",
    "        # end string for constructing the content URI\n",
    "        self.complement_end = \".txt\\', \\'mimeType\\': \\'text/plain\\'}\"\n",
    "                               \n",
    "\n",
    "\n",
    "class Input_Data:\n",
    "    def __init__(self, Route):\n",
    "        #Store the path to the input file\n",
    "        self.Route = Route\n",
    "    \n",
    "    def Data_Sent_Filt(self):\n",
    "        #Read the input file and return a DataFrame with only \"Id_Model\" and \"Message\" columns.\n",
    "        df = pd.read_excel(self.Route)\n",
    "        Data = df.loc[:,['Id_Model','Message']]\n",
    "        return Data\n",
    "    \n",
    "    def Data_Sent_All(self):\n",
    "        #Read the input file and return a DataFrame with all columns.\n",
    "        df = pd.read_excel(self.Route)\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "class Data_Frame:\n",
    "    def __init__(self, Data):\n",
    "        self.Data = Data\n",
    "        #Store the input data in the instance.\n",
    "    def Transform(self):\n",
    "        #Filter the data to only include the rows where the \"Message\" column is not null.\n",
    "        All_Clean = self.Data\n",
    "        Sentimentnot = All_Clean[All_Clean.Message.notnull()]\n",
    "        return Sentimentnot\n",
    "       \n",
    "\n",
    "class Generator:\n",
    "    def __init__(self, Sentiment,Path):\n",
    "        #Store the sentiment data and the path for the output files.\n",
    "        self.Sentiment = Sentiment\n",
    "        self.Path = Path\n",
    "        \n",
    "    def Iterator(self):\n",
    "        #Create a list of sentiment data and generate a text file for each sentiment in the list.\n",
    "        df = self.Sentiment\n",
    "        Sentiment_df = df['Message'] \n",
    "        General_list = Sentiment_df.to_numpy().tolist()\n",
    "        New_df = pd.DataFrame (General_list, columns = ['Sentiment'])\n",
    "        \n",
    "        for i in range(len(New_df)):\n",
    "            df_fn = (New_df.loc[i, 'Sentiment'])\n",
    "            new_list = [df_fn]\n",
    "            df_second = pd.DataFrame(new_list, columns = [''])\n",
    "            df_second.to_csv(f\"{self.Path}{i}.txt\",index=False,header=False)\n",
    "        \n",
    "        return New_df \n",
    "    \n",
    "    \n",
    "class Generate_path:\n",
    "    def __init__(self, Senti_df,Path):\n",
    "        self.Senti_df = Senti_df\n",
    "        self.Path = Path\n",
    "         \n",
    "    def paths_jsl(self, a, b):\n",
    "        \n",
    "        #Generates file paths for sentiment data and saves them to a .csv file.\n",
    "        \n",
    "        #Args:\n",
    "        #    a (str): The beginning of the file name.\n",
    "        #    b (str): The end of the file name.\n",
    "            \n",
    "        #Returns:\n",
    "        #    DataFrame: A DataFrame containing the generated file paths.\n",
    "        \n",
    "        df = self.Senti_df\n",
    "        row_max = (range(len(df)))\n",
    "        print(\"number of registres is: \" + str(row_max))\n",
    "        new_list  = df.to_numpy().tolist()\n",
    "        list_names = range(len(new_list))\n",
    "        list_paths = [] \n",
    "        \n",
    "        for i in list_names:\n",
    "            c = str(i)\n",
    "            Paths = a + c + b\n",
    "            list_paths.append(Paths)\n",
    "        \n",
    "        New_df = pd.DataFrame (list_paths, columns = ['Paths_off_Sentiment'])\n",
    "        New_df.to_csv(f'{self.Path}Prediction_Main_Batch.jsonl',index=False,header=False,quotechar=' ')\n",
    "        return New_df\n",
    "        \n",
    "        \n",
    "\n",
    "class generate_list:\n",
    "    #Generates a list of formatted integers with a maximum length of `files_user`.\n",
    "    def create_list(self,files_user):  \n",
    "        my_list = []\n",
    "        for i in range(1,files_user+1):\n",
    "            my_list.append(i)\n",
    "        formatter = \"{:02d}\".format\n",
    "        my_list = list(map(formatter, my_list))\n",
    "        return my_list\n",
    "            \n",
    "\n",
    "\n",
    "class Input_Result:\n",
    "    def __init__(self, Result):\n",
    "        # Result (str): Path to the result file.\n",
    "        self.Result = Result\n",
    "    \n",
    "    def Data_Out(self):\n",
    "        ## Define column names for the resulting DataFrame\n",
    "        columts = ['1', '2', '3','4','5','Order','Sentiment']\n",
    "        ## Read the result file and return the resulting DataFrame\n",
    "        Data = pd.read_csv(self.Result, names=columts,header=None, sep='/')\n",
    "        return Data\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "def generator_0 (count_files):\n",
    "    #Read batch prediction\n",
    "    for i in count_files:\n",
    "        Results = Input_Result(i)\n",
    "        Data_Result = Results.Data_Out()\n",
    "        Data_Recl = Data_Result.loc[:,['Order','Sentiment']]\n",
    "        yield Data_Recl\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "def generator_1(Data_Recl):\n",
    "    #Extract numeric values\n",
    "    df_num = pd.DataFrame()\n",
    "    df_num = df_num.fillna(0)\n",
    "    for i in Data_Recl.columns:\n",
    "        df_num[i]=Data_Recl [i].str.extract('(\\d+(?:\\.\\d+)?)')\n",
    "    yield df_num\n",
    "\n",
    "\n",
    "    \n",
    "def cycle_1(primer_g,a,row_max,df_final):\n",
    "    #Combine results from two generators\n",
    "    while a != row_max:\n",
    "        state_gene_1 = next(primer_g)\n",
    "        segundo_g = generator_1(state_gene_1)\n",
    "        state_gene_2 = next(segundo_g)\n",
    "\n",
    "        df_final =pd.concat([df_final,state_gene_2],ignore_index=True)\n",
    "        a = int(len(df_final))\n",
    "        \n",
    "    return df_final\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "\"\"\"This is the main code to start the program in this part we call the different objects\"\"\"\n",
    "\n",
    "def run():\n",
    "    \n",
    "    #Call Params to find read data\n",
    "    Params = Param()\n",
    "    Route_m = Params.file_input\n",
    "    print(\"The Params is: Ok\")\n",
    "    \n",
    "    \n",
    "    #Extract the Data Filt\n",
    "    All_Data = Input_Data(Route_m)\n",
    "    Data_1 = All_Data.Data_Sent_Filt()\n",
    "    print(\"The Data is: Ok\")\n",
    "    \n",
    "    \n",
    "    #Extract the Sentiment \n",
    "    Extract = Data_Frame(Data_1)\n",
    "    Data_Sentiment = Extract.Transform()\n",
    "    print(\"The sentiment export to list is: Ok\")\n",
    "    \n",
    "    \n",
    "    #Generate Data files txt\n",
    "    Variable_S = Generator(Data_Sentiment, Params.Processing_Batch)\n",
    "    Sentiments = Variable_S.Iterator()\n",
    "    print (\"The sentiment already exported to txt : Ok \")\n",
    " \n",
    "    \n",
    "    #Generate list with paths of sentiments \n",
    "    list_sent = Generate_path(Data_Sentiment, Params.Path_Control)\n",
    "    jsonl = list_sent.paths_jsl(Params.complement_ini, Params.complement_end)\n",
    "    print (\"The Paths  prediction exported : OK \" )\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Batch prediction of sentiments\n",
    "    output_files= batch_prediction_job(Params.project_id, \n",
    "                                        Params.location,                     \n",
    "                                        #change depend of the model offsite - onsite\n",
    "                                        Params.model_id_on_site, \n",
    "                                        Params.job_display_name,\n",
    "                                        Params.input_uri,\n",
    "                                        Params.output_uri)\n",
    "    print(\"Prediction Batch: ok\")\n",
    "    \n",
    "    #fix files output batch prediction\n",
    "    output_files.pop(0)\n",
    "    string = \"gs://batch_predictions_sentiment/\"\n",
    "    new_list = list(map(lambda x: string + str(x), output_files)) \n",
    "    print('files of batch is : ok')\n",
    "    \n",
    "    \n",
    "    #Extract the  ALL Data \n",
    "    Data_2 = All_Data.Data_Sent_All()\n",
    "    print(\"The Data Model is: Ok\")\n",
    "    \n",
    "    \n",
    "    #Extract the Sentiment \n",
    "    Extract = Data_Frame(Data_2)\n",
    "    Data_Sentiment = Extract.Transform()\n",
    "    print(\"The sentiment export to list is: Ok\")\n",
    "    \n",
    "    #concat and organize the data of sentiment\n",
    "    df_final = pd.DataFrame()\n",
    "    primer_g = generator_0(new_list)\n",
    "    a = 0\n",
    "    row_max = (int(len(Data_Sentiment)))\n",
    "    print(\"number of registres is: \" + str(row_max))\n",
    "    df_final = cycle_1(primer_g,a,row_max,df_final)\n",
    "    \n",
    "    #Order and index of dataframe\n",
    "    print(\"Data_frame is complete: OK\")\n",
    "    df_order = df_final.sort_values('Order',ascending=True) \n",
    "    df_order['Order'] = df_order['Order'].astype(int)\n",
    "    df_order = df_order.set_index('Order')\n",
    "    key_df  = pd.merge(Data_Sentiment, df_order, left_index=True, right_index=True)\n",
    "    \n",
    "    #Rename columns\n",
    "    key_df.rename(columns = {'Sentiment_y':'Sentiment_M', 'Sentiment_x':'Sentiment_H'}, inplace = True)\n",
    "    \n",
    "    #Export file\n",
    "    key_df.to_excel(\"data/sentiment.xlsx\",index=False)\n",
    "    print(\"The file is  : OK\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8ec2b30-540c-45b9-9512-7e283d967609",
   "metadata": {},
   "source": [
    "This code performs a batch prediction job on Google AI Platform, using an AI model and input data stored in Google Cloud Storage (GCS). The code uses the Google Cloud Storage and AI Platform APIs, as well as the Pandas and Numpy libraries.\n",
    "\n",
    "The main function, batch_prediction_job, submits a batch prediction job using the specified AI Platform model, source and destination. The function returns a list of the names of the files in the GCS destination location that contain the prediction results. The function uses the AI Platform API to get a reference to the model and submit the batch prediction job. It also uses the Google Cloud Storage API to get a reference to the GCS destination bucket and retrieve the names of the prediction result files.\n",
    "\n",
    "The Param class defines a set of parameters that are used by the code, including the project ID, model IDs, input and output URIs for the batch predictions, location for the cloud services, display name for the batch prediction job, and paths for processing and controlling batch data.\n",
    "\n",
    "The Input_Data class reads the input file specified in the Route parameter and returns either a DataFrame with only the \"Id_Model\" and \"Message\" columns or a DataFrame with all columns.\n",
    "\n",
    "The Data_Frame class transforms the input data by filtering the data to only include the rows where the \"Message\" column is not empty, and then constructs a JSONL file in the format required by the AI Platform API for batch predictions. The class also uploads the resulting file to GCS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "local-pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
